{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "Using the code from the Basic Python Roundup lecture notebook, create three functions:\n",
    "\n",
    "1. `scrape_book_results_page(page_num, headers)`: This function takes a page number and a headers dictionary as arguments and returns a dictionary with the following keys:\n",
    "    - `page_url`: The URL of the books results page\n",
    "    - `response`: The Response object of that page\n",
    "    - `soup`: The BeautifulSoup object created from the source code\n",
    "    - `book_urls`: A list of the URLs for each book on this page\n",
    "\n",
    "\n",
    "2. `scrape_book_product_page(book_product_url, headers)`: This function takes a book product URL (the URL for the book product page) and a headers dictionary as arguments and returns a dictionary with the following keys:\n",
    "    - `book_url`: The URL of the book product page \n",
    "    - `response`: The Response object of that page\n",
    "    - `soup`: The BeautifulSoup object created from the source code\n",
    "\n",
    "\n",
    "3. `scrape_book_range(page_range, filename, headers)`: This function takes a page range (`range` object), a filename for the a CSV file, and a headers dictionary as arguments and will use the other two functions to scrape the book information for every book found in the specified page range. This book information should be saved as separate rows in a CSV file (see if you can include the CSV file writing code in this function).\n",
    "\n",
    "Make sure to include proper documentation (docstring) for your code.\n",
    "\n",
    "**Before writing to CSV**, make the following changes to the book data:\n",
    "\n",
    "1. Convert `price_in_pounds` value to `float` type.\n",
    "2. Convert `avg_rating` to `int` type.\n",
    "3. Extract the number of available books from the `num_books_available` string and convert to `int` type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import csv\n",
    "import re\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.104 Safari/537.36'}\n",
    "\n",
    "def scrape_book_results_page(page_num, headers=headers):\n",
    "    \"\"\"scrape_book_results_page docstring\"\"\"\n",
    "    \n",
    "    book_page_urls = []\n",
    "    \n",
    "    page_url = f'https://books.toscrape.com/catalogue/page-{page_num}.html'\n",
    "    response = requests.get(page_url, headers = headers)\n",
    "    text = soup(response.text, 'html.parser')\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "            raise Exception(f'The status code is not 200! It is {response.status_code}.')\n",
    "    \n",
    "    book_divs = text.find_all('div', attrs = {'class': 'image_container'})\n",
    "    book_page_urls = [tag.find('a').get('href') for tag in book_divs]\n",
    "    \n",
    "    return book_page_urls\n",
    "\n",
    "def scrape_book_product_page(book_url, headers=headers):\n",
    "    \"\"\"scrape_book_product_page docstring\"\"\"\n",
    "    \n",
    "    book_dict = {}\n",
    "    \n",
    "    book_url = f'https://books.toscrape.com/catalogue/{book_url}'\n",
    "    response = requests.get(book_url, headers = headers)\n",
    "    text = soup(response.text, 'html.parser')\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "            raise Exception(f'The status code is not 200! It is {response.status_code}.')\n",
    "    \n",
    "    title = text.find('div', attrs = {'class': 'col-sm-6 product_main'}).find('h1').string\n",
    "    price_in_pounds = text.find('p', attrs = {'class':'price_color'}).string\n",
    "    avg_rating_tag = text.find(lambda tag: 'star-rating' in tag.get('class') if tag.get('class') else False)\n",
    "    avg_rating = avg_rating_tag.get('class')[1]\n",
    "    li_tag = text.find('ul', attrs={'class':'breadcrumb'}).find_all('li')[2]\n",
    "    genre = li_tag.find('a').string\n",
    "    tr_tag = text.find('table', attrs = {'class':'table table-striped'}).find_all('tr')[0]\n",
    "    upc = tr_tag.find('td').string\n",
    "    num_books_available = text.find('p', attrs = {'class':'instock availability'}).get_text()\n",
    "\n",
    "    book_dict['title'] = title\n",
    "    book_dict['price_in_pounds'] = price_in_pounds\n",
    "    book_dict['avg_rating'] = avg_rating\n",
    "    book_dict['genre'] = genre\n",
    "    book_dict['upc'] = upc\n",
    "    book_dict['num_books_available'] = num_books_available.replace('\\n', '').strip()\n",
    "\n",
    "    return book_dict\n",
    "\n",
    "def scrape_book_range(page_range, filename, headers=headers):\n",
    "    \"\"\"scrape_book_range docstring\"\"\"\n",
    "\n",
    "    book_descriptions = []\n",
    "    \n",
    "    for page in range(1,page_range+1):\n",
    "        book_urls = scrape_book_results_page(page)\n",
    "        for book in range(len(book_urls)):\n",
    "            title = scrape_book_product_page(book_urls[book])\n",
    "            book_descriptions.append(title)\n",
    "    \n",
    "    import csv\n",
    "\n",
    "    with open(filename, 'w', encoding = 'utf-8', newline='') as csvfile:\n",
    "        book_writer = csv.writer(csvfile)\n",
    "        headers = ['title', 'price_in_pounds', 'avg_rating', 'genre', 'upc', 'num_books_available']\n",
    "        book_writer.writerow(headers)\n",
    "        for book_dict in book_descriptions:\n",
    "            book_writer.writerow(book_dict[col] for col in headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "Take the code you've written above and create a module called `books2scrape`. This is just a file called `books2scrape` with a `py` extension. Make sure the module is located in your homework notebook working directory. Once you've created this module, import it and try to run the final function again.\n",
    "\n",
    "What is the benefit of moving this code to a module? How does the functionality of a module compare to a class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import books2scrape\n",
    "\n",
    "books2scrape.scrape_book_range(page_range, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Written Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It far reduces the clutter of code present in the compiler and works just as efficiently as a class given its complexity. However, if it were to employ more functions being called by the main function (scrape_book_range), then creating a class would be beneficial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
